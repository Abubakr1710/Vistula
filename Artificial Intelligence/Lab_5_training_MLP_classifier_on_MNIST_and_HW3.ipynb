{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 14pt;\">Prof. Krzysztof Rybinski</div><br/><br/>\n",
    "<div style=\"font-size: 22pt;\"><b>Artificial Intelligence course</b></div><br/><br/>\n",
    "<div style=\"font-size: 18pt;\">LAB 5.3</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- Predicting handwritten digits in MNIST dataset with MLP</div><br/><br/>\n",
    "<div style=\"font-size: 18pt;\">- Homework 3 described at the end of this Jupyter Notebook</div><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:21:42.701445Z",
     "start_time": "2018-11-13T15:21:39.648435Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 16:51:05.190013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 16:51:05.343238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:51:05.343253: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 16:51:06.027541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:51:06.027600: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:51:06.027608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check MNIST data information\n",
    "# https://en.wikipedia.org/wiki/MNIST_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:02.781102Z",
     "start_time": "2018-11-13T15:29:02.369623Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = mnist.load_data()\n",
    "\n",
    "(Xtrain, ytrain), (Xtest, ytest) = dataset\n",
    "\n",
    "n_train = len(Xtrain)\n",
    "n_test = len(Xtest)\n",
    "\n",
    "n_features = 28*28\n",
    "\n",
    "Xtrain = Xtrain.reshape( n_train, n_features )\n",
    "Xtest  = Xtest.reshape( n_test, n_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:02.781102Z",
     "start_time": "2018-11-13T15:29:02.369623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtrain[10002], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:02.787949Z",
     "start_time": "2018-11-13T15:29:02.783514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:17.565311Z",
     "start_time": "2018-11-13T15:29:17.559317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:32.437992Z",
     "start_time": "2018-11-13T15:29:32.433262Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:45:27.566378Z",
     "start_time": "2018-11-13T15:45:27.562418Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check info on MLPClassifer in sklearn\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:02.148932Z",
     "start_time": "2018-11-13T15:45:28.037088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.72795309\n",
      "Iteration 2, loss = 1.13699118\n",
      "Iteration 3, loss = 0.62809029\n",
      "Iteration 4, loss = 0.39398408\n",
      "Iteration 5, loss = 0.28085362\n",
      "Iteration 6, loss = 0.22020077\n",
      "Iteration 7, loss = 0.17910712\n",
      "Iteration 8, loss = 0.14886341\n",
      "Iteration 9, loss = 0.13145409\n",
      "Iteration 10, loss = 0.12516984\n",
      "Iteration 11, loss = 0.11479833\n",
      "Iteration 12, loss = 0.12069811\n",
      "Iteration 13, loss = 0.10615755\n",
      "Iteration 14, loss = 0.09644742\n",
      "Iteration 15, loss = 0.09330628\n",
      "Iteration 16, loss = 0.09608804\n",
      "Iteration 17, loss = 0.09326367\n",
      "Iteration 18, loss = 0.09209983\n",
      "Iteration 19, loss = 0.08820608\n",
      "Iteration 20, loss = 0.08737311\n",
      "Iteration 21, loss = 0.08302533\n",
      "Iteration 22, loss = 0.08539663\n",
      "Iteration 23, loss = 0.07523974\n",
      "Iteration 24, loss = 0.06512946\n",
      "Iteration 25, loss = 0.05983737\n",
      "Iteration 26, loss = 0.07222509\n",
      "Iteration 27, loss = 0.05842003\n",
      "Iteration 28, loss = 0.06605258\n",
      "Iteration 29, loss = 0.06295160\n",
      "Iteration 30, loss = 0.06510983\n",
      "Iteration 31, loss = 0.06677539\n",
      "Iteration 32, loss = 0.06521422\n",
      "Iteration 33, loss = 0.05911636\n",
      "Iteration 34, loss = 0.05276646\n",
      "Iteration 35, loss = 0.07200974\n",
      "Iteration 36, loss = 0.06012323\n",
      "Iteration 37, loss = 0.04554903\n",
      "Iteration 38, loss = 0.04863343\n",
      "Iteration 39, loss = 0.05594988\n",
      "Iteration 40, loss = 0.05355700\n",
      "Iteration 41, loss = 0.04811946\n",
      "Iteration 42, loss = 0.04681802\n",
      "Iteration 43, loss = 0.05803351\n",
      "Iteration 44, loss = 0.05941513\n",
      "Iteration 45, loss = 0.04459348\n",
      "Iteration 46, loss = 0.03971595\n",
      "Iteration 47, loss = 0.04882680\n",
      "Iteration 48, loss = 0.03730318\n",
      "Iteration 49, loss = 0.04117726\n",
      "Iteration 50, loss = 0.03922432\n",
      "Iteration 51, loss = 0.05785047\n",
      "Iteration 52, loss = 0.04549246\n",
      "Iteration 53, loss = 0.04373325\n",
      "Iteration 54, loss = 0.04729249\n",
      "Iteration 55, loss = 0.04210569\n",
      "Iteration 56, loss = 0.04449370\n",
      "Iteration 57, loss = 0.03876299\n",
      "Iteration 58, loss = 0.03805331\n",
      "Iteration 59, loss = 0.04587259\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MLPClassifier in module sklearn.neural_network._multilayer_perceptron object:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : array-like of shape(n_layers - 2,), default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      Strength of the L2 regularization term. The L2 regularization term\n",
      " |      is divided by the sample size when added to the loss.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`.\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : float, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : float, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      If early stopping is False, then the training stops when the training\n",
      " |      loss does not improve by more than tol for n_iter_no_change consecutive\n",
      " |      passes over the training set.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True.\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'.\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float or None\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |      If `early_stopping=True`, this attribute is set ot `None`. Refer to\n",
      " |      the `best_validation_score_` fitted attribute instead.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |  \n",
      " |  validation_scores_ : list of shape (`n_iter_`,) or None\n",
      " |      The score at each iteration on a held-out validation set. The score\n",
      " |      reported is the accuracy score. Only available if `early_stopping=True`,\n",
      " |      otherwise the attribute is set to `None`.\n",
      " |  \n",
      " |  best_validation_score_ : float or None\n",
      " |      The best validation score (i.e. accuracy score) that triggered the\n",
      " |      early stopping. Only available if `early_stopping=True`, otherwise the\n",
      " |      attribute is set to `None`.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has run.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  MLPRegressor : Multi-layer Perceptron regressor.\n",
      " |  BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E. \"Connectionist learning procedures.\"\n",
      " |  Artificial intelligence 40.1 (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio.\n",
      " |  \"Understanding the difficulty of training deep feedforward neural networks.\"\n",
      " |  International Conference on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  :arxiv:`He, Kaiming, et al (2015). \"Delving deep into rectifiers:\n",
      " |  Surpassing human-level performance on imagenet classification.\" <1502.01852>`\n",
      " |  \n",
      " |  :arxiv:`Kingma, Diederik, and Jimmy Ba (2014)\n",
      " |  \"Adam: A method for stochastic optimization.\" <1412.6980>`\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None)\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Trained MLP model.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to `log(predict_proba(X))`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-7.21315764e-316,  4.48225084e-316,  4.61576891e-315, ...,\n",
      "        -3.42869930e-315, -6.61571736e-317, -1.56999069e-315],\n",
      "       [-3.93675466e-315, -3.39869887e-315, -8.24629737e-316, ...,\n",
      "        -1.07452594e-315,  1.46623886e-316,  1.51558417e-315],\n",
      "       [ 6.76678855e-316,  5.86751986e-316, -8.05952767e-316, ...,\n",
      "         3.89239446e-315,  1.52609922e-315,  1.88490680e-315],\n",
      "       ...,\n",
      "       [ 2.67193651e-315, -8.28785081e-316,  2.92723499e-315, ...,\n",
      "         7.28899998e-316, -2.44942808e-315,  1.53799076e-315],\n",
      "       [-6.61679145e-317, -2.09704222e-316, -9.71738861e-316, ...,\n",
      "        -1.36181471e-315, -2.54333841e-315, -9.29322040e-316],\n",
      "       [ 1.72680440e-315, -1.08575339e-315,  3.61767850e-316, ...,\n",
      "        -1.58814843e-316, -1.14917418e-315, -4.04725900e-315]]), array([[ 8.59494239e-03, -2.91255119e-02, -4.68029591e-02,\n",
      "        -2.73708909e-03,  6.80186867e-02,  2.98407835e-02,\n",
      "         5.41198841e-02, -1.68406503e-02, -2.75224619e-02,\n",
      "        -1.79543711e-02],\n",
      "       [-3.29624835e-02,  4.89105226e-02, -2.31613459e-02,\n",
      "         1.58345762e-02,  9.81463764e-02, -3.27007935e-02,\n",
      "        -4.88399256e-02,  1.05320832e-01,  2.25500106e-02,\n",
      "         1.00099502e-01],\n",
      "       [-8.64403990e-02,  2.49272945e-35,  8.08683249e-02,\n",
      "         1.24858895e-02,  3.63678870e-02,  6.76737912e-03,\n",
      "        -2.96591672e-02, -9.45176197e-02,  4.83421921e-02,\n",
      "         7.23480517e-02],\n",
      "       [ 1.61643117e-01, -2.76520102e-02,  4.41532422e-03,\n",
      "         6.26190376e-02, -3.41433744e-02, -6.35302551e-02,\n",
      "         2.74883178e-01, -9.25656376e-02,  2.81403441e-02,\n",
      "         7.29293738e-02],\n",
      "       [ 5.53328552e-02,  8.58792865e-02, -5.02106024e-02,\n",
      "         1.75744581e-01,  1.64355854e-01, -6.03942494e-03,\n",
      "         2.69746123e-02, -1.82431150e-01, -1.46881411e-01,\n",
      "         3.35016148e-02],\n",
      "       [ 1.28861807e-02,  1.70788206e-01,  5.05051466e-02,\n",
      "         7.38412612e-02,  2.05617322e-01, -5.63002063e-02,\n",
      "         4.66292097e-02,  9.21047148e-02,  8.94441182e-02,\n",
      "         4.77019180e-02],\n",
      "       [ 5.51614213e-02, -1.50406410e-01, -3.47601183e-03,\n",
      "         7.17086248e-02, -2.47618136e-02, -1.60892140e-02,\n",
      "        -1.77448328e-01, -7.42767348e-02,  4.47834753e-02,\n",
      "         4.29143869e-02],\n",
      "       [-6.29130644e-03,  2.33138598e-02,  5.01523526e-02,\n",
      "         5.30879188e-02,  8.49632791e-02,  8.32902222e-02,\n",
      "         8.23580345e-02,  4.63751695e-02,  1.16038470e-01,\n",
      "         7.66448830e-02],\n",
      "       [ 1.30665986e-01,  1.41162361e-01,  1.78851028e-01,\n",
      "         1.74390817e-01,  1.26179735e-01,  1.07837967e-01,\n",
      "         1.91839812e-02,  1.37951232e-01,  1.21726501e-01,\n",
      "         5.57109500e-02],\n",
      "       [-2.73143251e-02,  1.36285449e-01,  2.85929413e-02,\n",
      "         5.88680744e-02,  1.36189343e-01,  3.10932135e-02,\n",
      "        -3.45309109e-03,  1.32597495e-01,  5.14398278e-02,\n",
      "         1.30505658e-01],\n",
      "       [ 2.32248265e-02,  1.11876271e-01,  1.51232412e-01,\n",
      "         1.24863563e-01, -4.57702301e-02,  1.33007659e-01,\n",
      "         7.94107538e-02,  1.25841315e-01,  8.52324632e-02,\n",
      "         1.75853435e-02],\n",
      "       [-1.79314245e-01, -4.74435093e-02,  1.28649695e-01,\n",
      "        -1.70788766e-01,  4.87662020e-02,  1.26341222e-01,\n",
      "        -5.23419575e-02,  4.20108859e-03,  1.67514109e-01,\n",
      "         2.08684080e-01],\n",
      "       [ 2.58462766e-02,  1.47152745e-01, -2.06151770e-01,\n",
      "        -1.07769632e-01,  1.19828140e-01, -1.98402874e-01,\n",
      "        -1.20296604e-01, -3.99083181e-02, -5.96546924e-02,\n",
      "        -6.56674310e-02],\n",
      "       [ 3.77117493e-02,  4.91068528e-02,  9.40468162e-02,\n",
      "         4.08449987e-02,  1.34498597e-01,  3.32675081e-02,\n",
      "         4.83722400e-02,  1.11260339e-01,  5.15031584e-02,\n",
      "         1.52627285e-01],\n",
      "       [ 3.31674784e-02, -1.06498087e-02,  2.03697465e-02,\n",
      "         2.70338363e-02, -2.06287838e-02,  1.30072863e-02,\n",
      "        -6.28651492e-02, -2.35910215e-02,  6.36311118e-02,\n",
      "         3.54945413e-02],\n",
      "       [ 6.12957511e-04, -3.21348566e-03,  2.21084422e-02,\n",
      "        -3.79332709e-02,  8.64612960e-02,  4.97108389e-02,\n",
      "        -4.51148227e-02,  8.23014693e-02, -5.09079490e-02,\n",
      "         3.41643126e-02],\n",
      "       [ 4.35102969e-02, -3.57242899e-02, -5.84543464e-02,\n",
      "        -5.84700899e-03, -4.63191792e-02,  1.22009181e-01,\n",
      "         5.61822911e-02,  6.10755405e-02, -7.15547868e-03,\n",
      "         4.65053464e-02],\n",
      "       [-2.54600107e-01, -4.69549039e-02, -3.34396834e-03,\n",
      "        -7.65100412e-03,  1.45961553e-01,  8.45212090e-02,\n",
      "         7.52021835e-02,  7.95372705e-02,  1.99116948e-02,\n",
      "         1.05212980e-01],\n",
      "       [-3.58535608e-02, -1.93698948e-02, -3.28769008e-02,\n",
      "         8.30074591e-02, -5.89135147e-03,  4.73549810e-02,\n",
      "        -1.71989279e-01,  5.88809379e-02, -3.35949204e-02,\n",
      "        -2.32408858e-02],\n",
      "       [-3.99334357e-02,  5.42675635e-02,  4.36212082e-02,\n",
      "        -1.50199587e-03, -2.01232536e-02,  3.62456258e-02,\n",
      "         8.96564650e-02, -4.30099401e-02,  5.51477951e-02,\n",
      "        -8.61761293e-02],\n",
      "       [ 1.13135054e-01,  4.78456045e-02, -6.17092606e-02,\n",
      "         1.49659203e-01,  1.46323441e-02,  1.23153470e-01,\n",
      "        -6.91728483e-02,  5.78388641e-02,  7.42904615e-02,\n",
      "         1.11293312e-01],\n",
      "       [-7.38183428e-02,  9.93015867e-02,  1.41669928e-01,\n",
      "         1.37946430e-01, -4.98230624e-03,  4.42897190e-02,\n",
      "        -1.37687987e-02,  1.39265085e-01,  1.01363957e-01,\n",
      "         2.73875020e-02],\n",
      "       [-1.32115943e-01, -4.90839645e-02,  3.22836152e-02,\n",
      "        -1.91784416e-01,  1.62907124e-01,  1.32719058e-01,\n",
      "         1.39097579e-01, -1.79178672e-01,  4.58583628e-02,\n",
      "         2.17017174e-01],\n",
      "       [-1.74749737e-01, -2.61141516e-02, -1.64287884e-01,\n",
      "        -1.45553098e-01,  1.06181106e-01,  2.84557084e-02,\n",
      "         1.34565658e-01,  1.67950077e-01,  6.06389262e-02,\n",
      "         1.63069003e-01],\n",
      "       [ 1.99980962e-01,  1.89451546e-01,  8.51235597e-02,\n",
      "         7.32369798e-02, -3.51795533e-02,  1.06500907e-01,\n",
      "         9.19472331e-02,  7.38552378e-02, -3.30809978e-02,\n",
      "        -1.36317002e-01],\n",
      "       [ 9.48389010e-02,  2.98508403e-02,  9.02610959e-02,\n",
      "         2.88404262e-02, -1.04826858e-01, -1.35675199e-02,\n",
      "         7.56929921e-03,  9.26249111e-02, -1.70050563e-02,\n",
      "         6.64048614e-02],\n",
      "       [ 4.58517803e-02, -8.32357649e-03,  1.07243427e-01,\n",
      "         1.83744992e-02, -9.95859588e-02,  5.46179692e-03,\n",
      "        -6.11322795e-02,  4.00558955e-02, -7.47705554e-02,\n",
      "        -1.49481676e-01],\n",
      "       [-9.23585924e-02,  1.04225211e-01,  7.09725468e-03,\n",
      "        -3.08368160e-02,  2.05252460e-02, -8.31534902e-02,\n",
      "         1.75129655e-01, -1.84788814e-01,  7.28062567e-02,\n",
      "        -1.27537137e-01],\n",
      "       [ 1.24052526e-01,  5.28629956e-02,  6.09705914e-02,\n",
      "         1.08448128e-01,  1.44154714e-01,  7.66781068e-02,\n",
      "         1.28538673e-01,  8.10937748e-02,  7.51964426e-02,\n",
      "         7.03253946e-02],\n",
      "       [-8.23365184e-02, -3.89503848e-02,  8.55788472e-02,\n",
      "         1.06078681e-01, -1.78165255e-01,  2.00964680e-02,\n",
      "         3.70455872e-02, -2.92557488e-02,  4.47494959e-02,\n",
      "        -9.15891697e-03],\n",
      "       [-4.55460397e-03,  7.71822820e-02,  7.65881567e-02,\n",
      "        -4.85868518e-02,  1.38610608e-01,  4.92323981e-02,\n",
      "         9.24454101e-02,  5.15314441e-02,  8.79323333e-03,\n",
      "         8.25966729e-02],\n",
      "       [ 1.50996258e-01, -1.13227110e-01,  1.58989208e-01,\n",
      "         2.07168916e-02, -1.43217258e-02,  8.33134021e-02,\n",
      "         1.14603744e-01,  1.27867036e-01,  2.55056442e-02,\n",
      "         1.01785029e-01],\n",
      "       [ 1.35136731e-02, -3.96771100e-02, -5.33586412e-02,\n",
      "        -4.72352045e-03, -1.17559744e-01, -9.20698914e-02,\n",
      "        -2.17515168e-02, -4.50752945e-02,  5.98078312e-04,\n",
      "        -5.01102174e-02],\n",
      "       [ 1.23314982e-01,  5.75039441e-02, -9.30040455e-02,\n",
      "        -1.39614766e-01,  4.29846252e-02,  8.88561150e-02,\n",
      "        -1.04353052e-01, -1.04572120e-01,  9.09543527e-02,\n",
      "         1.90607049e-01],\n",
      "       [-4.34158649e-02,  4.16603873e-02,  4.21317055e-02,\n",
      "         9.69509135e-02,  7.89177379e-03,  7.21800484e-02,\n",
      "         6.91163181e-02,  7.88829955e-03,  1.12488055e-01,\n",
      "         6.73171486e-02],\n",
      "       [ 1.48587510e-01, -1.82518393e-01,  1.37056428e-01,\n",
      "         6.78980537e-02,  2.39750801e-02,  4.84426737e-03,\n",
      "         6.65435578e-02,  1.10004585e-01,  4.53846949e-02,\n",
      "         8.89004011e-02],\n",
      "       [ 1.99923173e-01,  5.94476644e-02, -2.27888038e-02,\n",
      "         1.44086618e-01, -6.23466056e-02, -7.03133284e-02,\n",
      "         1.98424824e-01, -1.75951911e-02,  7.20982318e-02,\n",
      "         1.98769709e-01],\n",
      "       [-1.82908461e-01, -5.84906410e-02,  1.30283532e-01,\n",
      "         1.18277501e-01,  1.54879936e-01, -1.53283619e-01,\n",
      "         1.41623970e-02, -1.44874172e-01, -1.19635492e-01,\n",
      "        -8.19379810e-02],\n",
      "       [-1.63206060e-01,  1.03530699e-01, -1.91626283e-01,\n",
      "        -1.59237343e-01, -2.41234778e-01, -1.23225000e-01,\n",
      "        -1.05109399e-01, -2.27351245e-01,  1.09485248e-01,\n",
      "         9.69292262e-02],\n",
      "       [-9.97263174e-02, -1.09837519e-01, -5.91283673e-02,\n",
      "        -2.15483819e-03, -3.99062094e-02, -2.33581296e-03,\n",
      "        -4.62582235e-02, -5.26256413e-02,  2.57481752e-02,\n",
      "         1.97115609e-02],\n",
      "       [ 2.84840888e-02, -2.77380074e-02, -6.52695182e-02,\n",
      "        -9.17146580e-04, -1.10923414e-01,  4.97153679e-02,\n",
      "        -1.48139884e-02,  9.55908987e-02,  9.72341289e-02,\n",
      "        -7.98526738e-02],\n",
      "       [-9.16322086e-02, -5.44728286e-02, -1.25582965e-01,\n",
      "        -6.52173184e-02, -5.21701157e-02, -1.62577726e-01,\n",
      "        -4.05700848e-02, -9.02001582e-02, -9.26414933e-02,\n",
      "        -2.00020263e-01],\n",
      "       [ 1.68373196e-01, -1.85635768e-01,  2.51110526e-02,\n",
      "         6.55328070e-02,  6.77411759e-02,  1.85417107e-02,\n",
      "         2.01857277e-01, -1.05014561e-01,  1.08855039e-01,\n",
      "         8.08527811e-02],\n",
      "       [ 2.09098492e-03, -1.10342644e-04,  1.28837445e-01,\n",
      "         7.79659380e-02, -8.37939764e-02, -3.22243224e-02,\n",
      "        -3.87691737e-02,  3.78225050e-02, -3.18631437e-02,\n",
      "        -3.68201060e-02],\n",
      "       [-1.00477502e-02,  4.42659605e-02,  4.17576085e-02,\n",
      "        -3.27531872e-02, -1.86548853e-03, -1.44115968e-01,\n",
      "        -7.66294820e-02, -1.20947821e-01, -3.02514410e-02,\n",
      "        -5.84069025e-03],\n",
      "       [ 6.93059455e-02, -3.06038772e-02,  3.36325293e-02,\n",
      "        -6.16295543e-02, -5.82049627e-02,  2.62326649e-02,\n",
      "        -2.55270624e-02,  5.18607602e-03,  3.42444848e-02,\n",
      "        -3.53235048e-02],\n",
      "       [ 1.44889077e-02,  3.66033577e-02, -1.02510226e-01,\n",
      "        -4.54572104e-02, -5.65070416e-02,  5.60825270e-02,\n",
      "         6.06410254e-02, -9.35975913e-02, -5.13211355e-03,\n",
      "        -3.68401763e-02],\n",
      "       [-2.27757257e-01,  2.02870294e-01, -1.75172243e-02,\n",
      "         1.32182403e-01,  1.23000237e-01,  1.93107523e-01,\n",
      "        -2.45057186e-02, -6.23632065e-02,  7.41557616e-03,\n",
      "        -3.41599561e-02],\n",
      "       [-1.64984888e-01,  6.87713255e-02,  3.88894161e-02,\n",
      "         9.29050926e-02, -4.81985967e-02, -1.02463798e-02,\n",
      "         6.32601221e-02,  8.55053153e-02, -1.28355635e-02,\n",
      "        -1.74432566e-02],\n",
      "       [ 1.50945934e-01,  1.84158666e-01,  5.63573222e-02,\n",
      "         1.30239824e-01,  1.18813991e-01,  2.09331077e-01,\n",
      "         1.60110123e-01, -1.10801067e-01,  4.54484229e-02,\n",
      "         6.88826034e-02],\n",
      "       [-1.97590905e-02,  1.49108921e-01,  1.07109488e-01,\n",
      "         1.88028476e-01,  1.40002277e-01,  1.90756054e-01,\n",
      "        -1.28718174e-01,  1.42615242e-01,  1.03791143e-01,\n",
      "         1.89855660e-01],\n",
      "       [ 2.01937301e-01, -3.13501884e-02,  1.78049205e-01,\n",
      "         7.16599498e-02, -1.62038811e-01,  2.25846319e-02,\n",
      "        -1.16242804e-01, -1.18181851e-01,  6.14031393e-02,\n",
      "         8.41291722e-02],\n",
      "       [-9.75232689e-02,  8.56453664e-02,  7.50404395e-02,\n",
      "         1.66409030e-01, -3.24813018e-02,  1.58025619e-01,\n",
      "        -8.11507921e-02, -5.34926120e-02,  5.41156242e-02,\n",
      "         5.54182563e-02],\n",
      "       [-3.82984214e-02, -7.95217305e-02,  7.01999200e-02,\n",
      "         6.48965552e-02,  7.70848974e-02,  2.13799457e-01,\n",
      "        -1.26482232e-01,  1.64341342e-01,  1.47188014e-01,\n",
      "         5.16810313e-02],\n",
      "       [-1.20086505e-01, -8.43525602e-02,  4.99152269e-02,\n",
      "        -1.50457003e-01, -1.45507242e-01,  2.29832758e-02,\n",
      "         9.54088767e-02,  1.67276036e-01,  1.46302866e-01,\n",
      "         9.17968683e-02],\n",
      "       [ 4.88183819e-02, -1.07893858e-01, -1.12572090e-01,\n",
      "        -2.98951236e-02, -1.92538183e-01,  2.47513486e-02,\n",
      "        -5.29764047e-02, -7.08013346e-02,  1.16285476e-01,\n",
      "         1.10003398e-01],\n",
      "       [ 1.60597045e-01,  2.04723408e-02,  1.09744022e-01,\n",
      "        -5.47334370e-03, -3.70880944e-02,  2.73204722e-02,\n",
      "         9.70650078e-02,  8.47282265e-02,  2.48437621e-02,\n",
      "         7.56294133e-03],\n",
      "       [-7.36686403e-03, -1.98617550e-02,  1.50436285e-02,\n",
      "        -3.60252759e-02,  8.84732955e-03,  1.05773482e-01,\n",
      "         7.04405791e-02,  1.07816290e-02,  1.08727460e-01,\n",
      "         2.53225238e-02],\n",
      "       [ 4.43579805e-02,  1.00073205e-01, -3.25933584e-02,\n",
      "         6.80847530e-02, -4.32704836e-02,  1.48565754e-01,\n",
      "         7.55508372e-03, -5.45756265e-03,  5.60932169e-02,\n",
      "         5.20855923e-02],\n",
      "       [-1.51843374e-01, -8.79089693e-02, -1.83406772e-01,\n",
      "        -4.49517946e-02,  1.20689008e-01, -1.16100350e-01,\n",
      "        -6.25782616e-02,  1.47045659e-01, -7.59002666e-02,\n",
      "         1.19525932e-01],\n",
      "       [-1.33808086e-01,  3.62248260e-02, -1.81114550e-01,\n",
      "        -4.32137095e-02, -6.25139187e-03,  3.98889342e-02,\n",
      "        -6.88289182e-02, -5.25892532e-02, -6.66458315e-02,\n",
      "        -1.02716802e-01],\n",
      "       [-1.10662157e-01, -5.13013969e-02, -9.24361330e-02,\n",
      "        -9.20517924e-03, -4.82946589e-02,  5.85838544e-02,\n",
      "        -8.40446120e-02, -9.22674538e-02, -1.06650189e-01,\n",
      "        -8.38230476e-02],\n",
      "       [-1.08239682e-01,  7.93812018e-02,  6.83085639e-02,\n",
      "        -1.87301804e-02, -2.16966461e-02, -6.58704033e-02,\n",
      "        -7.57974324e-03, -1.13850239e-02,  6.54717485e-03,\n",
      "         5.52608192e-02],\n",
      "       [-5.42410610e-02, -3.58796192e-02,  1.51311492e-02,\n",
      "         8.27884177e-02,  1.99961784e-02, -7.39872818e-02,\n",
      "         1.12763687e-01, -1.31446985e-01, -1.77280641e-01,\n",
      "        -1.48886811e-01],\n",
      "       [-6.32333452e-02, -4.09778698e-03,  1.63963236e-02,\n",
      "         1.33271166e-01,  1.19282459e-02,  1.25414831e-01,\n",
      "        -1.99527815e-02, -1.16759271e-03,  5.43106116e-02,\n",
      "         1.15663588e-01],\n",
      "       [-4.44373680e-02, -1.43722187e-01, -1.51662867e-01,\n",
      "         1.14257567e-01,  1.82830012e-01,  1.77890087e-01,\n",
      "        -1.27871263e-01, -1.15598969e-01,  5.92678805e-02,\n",
      "        -1.15269592e-01],\n",
      "       [ 3.40973447e-02,  5.99881151e-02,  1.02989508e-01,\n",
      "         5.92416373e-03,  2.40327477e-02, -1.80143200e-01,\n",
      "        -4.50500148e-03,  5.59632400e-02, -2.27069075e-02,\n",
      "        -1.16130426e-01],\n",
      "       [ 1.47856805e-01, -1.54907608e-01,  6.27179744e-02,\n",
      "         9.80481533e-02,  8.98937806e-02, -3.90547922e-02,\n",
      "         1.30466866e-01,  6.12595418e-02,  6.71201708e-02,\n",
      "         1.35195923e-01],\n",
      "       [-3.03061054e-02, -1.43348684e-01,  1.03929383e-01,\n",
      "        -1.01704838e-01, -1.55624525e-01,  1.78187955e-01,\n",
      "         1.43430273e-01, -7.31470613e-02, -8.92869626e-02,\n",
      "         1.32100884e-02],\n",
      "       [ 3.40133583e-02, -2.04599648e-01,  4.50708662e-02,\n",
      "         6.99537363e-02,  1.11176673e-01,  1.08610416e-01,\n",
      "        -4.82870748e-02,  9.43203004e-02, -1.09557651e-01,\n",
      "         1.35195646e-01],\n",
      "       [ 6.99953300e-02,  1.17766603e-02,  6.94396069e-02,\n",
      "         1.18900939e-01,  1.51970120e-01, -1.92163949e-02,\n",
      "        -6.72985564e-02, -6.57088924e-03,  1.04926270e-01,\n",
      "         4.20706653e-02],\n",
      "       [-1.76644353e-01,  8.27459165e-02, -5.14800776e-03,\n",
      "         8.27678086e-02,  1.25857780e-01, -1.15903265e-01,\n",
      "         1.24612870e-01,  1.22531837e-02,  4.71870973e-02,\n",
      "        -9.88287832e-03],\n",
      "       [ 1.01276390e-01, -2.68102360e-02,  1.77545353e-01,\n",
      "         1.13241088e-01, -3.21503432e-02,  8.47721867e-02,\n",
      "        -6.17609293e-02,  1.81870838e-02,  2.68906684e-02,\n",
      "        -6.87905006e-02],\n",
      "       [-1.77179425e-01, -5.76178355e-02, -3.19316922e-02,\n",
      "        -1.99695237e-02, -1.21209378e-01, -3.72023441e-02,\n",
      "        -1.91707112e-01,  7.54674292e-02, -9.71389783e-02,\n",
      "        -6.04397709e-02],\n",
      "       [ 4.33636739e-02, -1.53731095e-01, -1.84593410e-01,\n",
      "        -1.22174408e-01, -1.03687863e-01, -2.03675023e-01,\n",
      "        -5.14246320e-02, -9.04100145e-02, -1.67559627e-01,\n",
      "        -3.36437423e-02],\n",
      "       [-3.10780115e-02,  9.13569764e-02,  4.77423148e-02,\n",
      "        -1.44761457e-02,  5.04444728e-02,  1.44955838e-02,\n",
      "         4.87746049e-02,  6.54902549e-02,  9.39682070e-02,\n",
      "         2.30707255e-03],\n",
      "       [-8.39574594e-02, -1.06053496e-01,  4.93808220e-02,\n",
      "        -5.23589987e-03,  1.87641278e-01,  3.18815224e-02,\n",
      "         1.67599938e-02, -1.01000737e-01, -1.01250548e-01,\n",
      "         1.22542235e-01],\n",
      "       [ 7.29944613e-02,  1.42354861e-01,  1.12420349e-01,\n",
      "         6.34197276e-02,  1.67667465e-01,  1.22272487e-01,\n",
      "         1.16263990e-02,  4.05812757e-02,  6.96927385e-02,\n",
      "         6.54907673e-02],\n",
      "       [ 2.05467182e-02, -7.48994861e-02,  3.98770993e-02,\n",
      "        -9.75285213e-02,  1.08974523e-01, -6.08982077e-02,\n",
      "        -7.29197884e-02,  1.53050005e-02,  3.80440418e-02,\n",
      "         4.94153325e-02],\n",
      "       [ 6.50573278e-02,  6.51987742e-03, -8.57758411e-03,\n",
      "         2.00667853e-02,  1.06583811e-02,  1.46923622e-02,\n",
      "        -8.63559598e-02,  4.68169212e-02,  8.01997671e-02,\n",
      "         3.57088904e-02],\n",
      "       [ 1.33097264e-01, -4.30664695e-02,  2.28060833e-01,\n",
      "         1.58033655e-01,  1.27179467e-01,  1.25088277e-01,\n",
      "         4.79040695e-02,  5.54603407e-02, -1.14269508e-01,\n",
      "        -8.12018175e-04],\n",
      "       [-1.40125202e-02, -1.85563936e-01, -9.18674524e-02,\n",
      "         7.85136902e-02,  4.25040310e-02,  1.37222239e-01,\n",
      "         6.27657892e-02,  3.49923940e-02,  1.31112701e-02,\n",
      "        -1.95628822e-02],\n",
      "       [-4.08982423e-02, -7.11358766e-02, -2.38169744e-02,\n",
      "         1.10883623e-01,  2.04434956e-01,  8.52070079e-02,\n",
      "         1.27771742e-01, -2.24452666e-02,  1.00042388e-01,\n",
      "         8.11994523e-02],\n",
      "       [ 2.71250208e-02,  1.55089511e-01,  7.67482152e-03,\n",
      "        -1.46816874e-01,  1.41106197e-01, -1.08321777e-01,\n",
      "         1.01205713e-02, -4.97727375e-02, -1.57282313e-01,\n",
      "         4.86494327e-02],\n",
      "       [ 8.09872115e-02, -9.59414162e-02, -3.04408925e-02,\n",
      "        -3.92002909e-02,  3.95812331e-02,  8.72642281e-03,\n",
      "         6.36527044e-02, -2.08440934e-02, -5.42358828e-03,\n",
      "         2.14704322e-02],\n",
      "       [ 5.15999052e-02,  1.00231949e-02,  1.04154252e-01,\n",
      "         7.69876971e-02,  4.01932841e-02,  2.76601914e-04,\n",
      "         1.12947653e-02,  3.71441201e-02,  8.97040026e-02,\n",
      "         5.11947279e-02],\n",
      "       [-1.24127372e-02, -2.93460686e-02, -1.97984968e-02,\n",
      "         7.70795097e-02, -2.40974834e-02, -5.62504223e-02,\n",
      "        -1.90310234e-01,  1.49597723e-01, -4.55604547e-02,\n",
      "         9.77433607e-02],\n",
      "       [-1.34275285e-01,  9.21708360e-02, -5.65287304e-02,\n",
      "        -9.40235670e-02, -2.40600125e-03, -6.36042321e-02,\n",
      "        -1.08647581e-01,  1.23808422e-01,  2.93279605e-02,\n",
      "         8.07403796e-02],\n",
      "       [ 3.55446852e-02,  1.26396986e-01,  1.53786053e-01,\n",
      "         1.35049957e-01,  2.23134091e-01,  2.36218859e-01,\n",
      "         1.53183501e-01, -9.48977711e-02, -7.50398645e-02,\n",
      "         2.50656555e-01],\n",
      "       [ 1.73038409e-01,  1.42930393e-01,  1.66659286e-01,\n",
      "        -1.00192161e-01,  7.91007014e-02,  2.43539863e-01,\n",
      "         9.02578017e-02,  1.42187546e-01,  3.69599327e-03,\n",
      "        -8.63333119e-02],\n",
      "       [-1.13282496e-01,  3.38722081e-02, -2.75760954e-02,\n",
      "         1.48672182e-01, -3.63449838e-02,  1.23571227e-01,\n",
      "         1.43715405e-02, -1.61852077e-02,  9.15540098e-02,\n",
      "        -6.57712568e-03],\n",
      "       [-1.53277723e-01, -6.87982001e-03, -1.49861821e-01,\n",
      "         8.66505464e-02, -9.25772390e-02,  9.84444212e-02,\n",
      "        -3.15169485e-02,  1.14815582e-01, -4.29545110e-02,\n",
      "        -1.06623957e-02],\n",
      "       [ 7.33724537e-02, -3.65145730e-03, -2.56616073e-02,\n",
      "        -4.77775235e-02,  4.66073891e-03, -3.76114076e-03,\n",
      "         5.69548001e-02,  4.04160709e-02, -3.46094859e-02,\n",
      "        -5.22891919e-02],\n",
      "       [ 1.52151777e-01,  6.69032076e-02,  6.11929970e-02,\n",
      "         5.41778793e-02,  5.94134464e-02,  3.87917874e-02,\n",
      "        -1.64300042e-01,  2.21156082e-01, -1.75683166e-01,\n",
      "         8.89426749e-02],\n",
      "       [-1.99161754e-02,  1.60915863e-01,  1.16190187e-01,\n",
      "         8.18336993e-02,  8.63127338e-02, -9.46274008e-02,\n",
      "         2.75367829e-02,  7.49193112e-02, -1.42627615e-02,\n",
      "        -7.75973195e-03],\n",
      "       [-5.57168758e-02, -1.14389622e-01, -3.74053040e-02,\n",
      "        -2.33581543e-03, -8.34232790e-02,  7.33822922e-02,\n",
      "         9.42841669e-02, -2.36482099e-02,  8.11161466e-03,\n",
      "        -2.39117354e-03],\n",
      "       [-1.50269482e-02,  8.90547254e-02, -8.47789274e-02,\n",
      "         2.51568827e-02,  9.00243615e-02, -1.62958172e-02,\n",
      "         2.04351296e-02,  9.30767386e-02, -3.11920376e-02,\n",
      "         4.89986789e-02],\n",
      "       [-1.09062755e-01,  3.01203571e-02,  2.02055986e-01,\n",
      "        -1.38461396e-01,  1.48270711e-01,  2.52578978e-01,\n",
      "         2.56721816e-01,  1.60097486e-01,  1.34707546e-01,\n",
      "         5.87708524e-02],\n",
      "       [-1.70127390e-01,  2.29682241e-01,  1.87921387e-01,\n",
      "        -1.62537333e-01, -1.57293095e-01,  1.76004253e-01,\n",
      "         1.55098981e-01,  6.69336332e-02, -1.27224102e-01,\n",
      "         1.52338594e-01],\n",
      "       [-4.51127882e-02, -1.42371530e-01,  2.86192385e-02,\n",
      "        -7.62630316e-02, -1.62475989e-02,  2.40804116e-02,\n",
      "         6.42019061e-02, -1.18205524e-01, -8.94367193e-03,\n",
      "        -1.66969691e-02]])]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0].shape\n",
    "#explain the dimension of the W matrix for the first (hidden) layer\n",
    "# 784 is the number of features (pixels) in the input layer, \n",
    "# 100 is the number of neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[1].shape\n",
    "#explain the dimension of the W matrix for the second (output) layer\n",
    "# 100 is the number of neurons in the hidden layer,\n",
    "# 10 is the number of neurons in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercepts_[0].shape\n",
    "#explain the dimension of the b (bias) vector for the first (hidden) layer\n",
    "# 100 is the number of neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercepts_[1].shape\n",
    "#explain the dimension of the b (bias) vector for the second (output) layer\n",
    "# 10 is the number of neurons in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:05.771427Z",
     "start_time": "2018-11-13T15:46:05.279063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9924166666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:06.285050Z",
     "start_time": "2018-11-13T15:46:06.215576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtest[120], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(Xtest[120].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:46.642228Z",
     "start_time": "2018-11-13T15:46:46.615128Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyMLP:\n",
    "    def __init__(self, n_input, n_hidden, n_output, random_seed = 0, activate='sigmoid', verbose=False):\n",
    "        np.random.seed( random_seed )\n",
    "        # biases for hidden layer\n",
    "        self.b_hidden = np.random.randn( 1,n_hidden )\n",
    "        # weights for hidden layer\n",
    "        self.w_hidden = np.random.randn( n_input, n_hidden ) / np.sqrt(n_input+n_hidden)    # Glorot Initialization\n",
    "        # biases for output layer\n",
    "        self.b_output = np.random.randn( 1, n_output )\n",
    "        # weights for hidden layer\n",
    "        self.w_output = np.random.randn( n_hidden, n_output ) / np.sqrt(n_hidden+n_output)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        if activate=='sigmoid':\n",
    "            self.activate = self.sigmoid\n",
    "            self.activate_der = self.sigmoid_der\n",
    "        else:\n",
    "            self.activate = self.tanh\n",
    "            self.activate_der = self.tanh_der\n",
    "\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "    def sigmoid_der(self,x):\n",
    "        g = 1.0/(1.0+np.exp(-x))\n",
    "        return g, g*(1.0-g)\n",
    "    \n",
    "    def tanh(self,x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def tanh_der(self,x):\n",
    "        g = np.tanh(x)\n",
    "        return g, 1.0-g**2\n",
    "\n",
    "    def softmax(self,x):\n",
    "        x -= np.max(x,axis=1,keepdims=True)\n",
    "        x  = np.exp(x)\n",
    "        x /= np.sum(x,axis=1,keepdims=True)\n",
    "        return x\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # X.shape = (m,n_input)\n",
    "        Z1 = X.dot(self.w_hidden) + self.b_hidden\n",
    "        # Z1.shape = (m,n_hidden)\n",
    "        A1 = self.activate( Z1 )\n",
    "        # A1.shape = (m,n_hidden)\n",
    "        Z2 = A1.dot(self.w_output) + self.b_output\n",
    "        # Z2.shape = (m,n_output)\n",
    "        A2 = self.softmax( Z2 )\n",
    "        # A2.shape = (m,n_output)\n",
    "        return A2\n",
    "    \n",
    "    def predict_class(self, X):\n",
    "        yhat = self.predict(X)\n",
    "        # pred.shape = (m,n_output)\n",
    "        # np.argmax( pred , axis=1 ).shape = (m,)\n",
    "        return np.argmax( yhat , axis=1 )\n",
    "    \n",
    "    def score(self,X,y):\n",
    "        return np.mean( self.predict_class(X) == y )\n",
    "    \n",
    "    # cross-entropy\n",
    "    def loss(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return - np.mean( np.log( yhat[ range(len(yhat)), y ] ) )\n",
    "    \n",
    "    def fit(self, Xtrain, ytrain, epochs = 100, learning_rate = 0.1):\n",
    "        m,_ = Xtrain.shape\n",
    "        \n",
    "        for iter in range(epochs):  \n",
    "            # Forward propagation\n",
    "            # X.shape = (m,n_input)\n",
    "            Z1 = Xtrain.dot(self.w_hidden) + self.b_hidden\n",
    "            # Z1.shape = (m,n_hidden)\n",
    "            A1,dZ1 = self.activate_der( Z1 )\n",
    "            # A1.shape = (m,n_hidden)\n",
    "            Z2 = A1.dot(self.w_output) + self.b_output\n",
    "            # Z2.shape = (m,n_output)\n",
    "            A2 = self.softmax( Z2 )\n",
    "            # A2.shape = (m,n_output)\n",
    "\n",
    "            # Backward propagation\n",
    "#             delta2 = (A2-ytrain_one_hot)/m\n",
    "            delta2 = A2\n",
    "            delta2[ range(len(delta2)), ytrain ] -= 1\n",
    "            delta2 /= len(delta2)\n",
    "        \n",
    "            delta1 = delta2.dot( self.w_output.T ) * dZ1\n",
    "\n",
    "            dw_output = A1.T.dot(delta2)\n",
    "            dw_hidden = Xtrain.T.dot(delta1)\n",
    "\n",
    "            db_output = np.sum( delta2, axis=0, keepdims=True )\n",
    "            db_hidden = np.sum( delta1, axis=0, keepdims=True )\n",
    "            \n",
    "            \n",
    "            # Gradient descent\n",
    "            self.w_hidden -= (learning_rate * dw_hidden)\n",
    "            self.b_hidden -= (learning_rate * db_hidden)\n",
    "            self.w_output -= (learning_rate * dw_output)\n",
    "            self.b_output -= (learning_rate * db_output)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(\"Loss after iteration %i: %f (score=%.2f%%)\" %(iter, self.loss(Xtrain, ytrain), 100.0*self.score(Xtrain,ytrain)))\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:47:48.517951Z",
     "start_time": "2018-11-13T15:47:48.511334Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = MyMLP(784, 100, 10, random_seed=0, activate='tanh', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T16:00:47.505723Z",
     "start_time": "2018-11-13T15:57:33.640998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 2.019299 (score=28.32%)\n",
      "Loss after iteration 1: 1.805563 (score=46.39%)\n",
      "Loss after iteration 2: 1.469206 (score=57.15%)\n",
      "Loss after iteration 3: 1.224532 (score=64.34%)\n",
      "Loss after iteration 4: 1.136829 (score=66.25%)\n",
      "Loss after iteration 5: 1.052258 (score=69.16%)\n",
      "Loss after iteration 6: 0.975614 (score=71.74%)\n",
      "Loss after iteration 7: 0.885285 (score=75.40%)\n",
      "Loss after iteration 8: 0.826698 (score=77.34%)\n",
      "Loss after iteration 9: 0.772416 (score=79.48%)\n",
      "Loss after iteration 10: 0.730379 (score=80.32%)\n",
      "Loss after iteration 11: 0.706912 (score=81.41%)\n",
      "Loss after iteration 12: 0.682639 (score=81.25%)\n",
      "Loss after iteration 13: 0.656874 (score=83.03%)\n",
      "Loss after iteration 14: 0.637254 (score=82.59%)\n",
      "Loss after iteration 15: 0.620134 (score=83.98%)\n",
      "Loss after iteration 16: 0.600467 (score=83.79%)\n",
      "Loss after iteration 17: 0.585694 (score=84.99%)\n",
      "Loss after iteration 18: 0.571758 (score=84.61%)\n",
      "Loss after iteration 19: 0.557487 (score=85.81%)\n",
      "Loss after iteration 20: 0.542769 (score=85.40%)\n",
      "Loss after iteration 21: 0.535428 (score=86.39%)\n",
      "Loss after iteration 22: 0.520722 (score=86.11%)\n",
      "Loss after iteration 23: 0.512988 (score=86.95%)\n",
      "Loss after iteration 24: 0.498913 (score=86.75%)\n",
      "Loss after iteration 25: 0.490065 (score=87.51%)\n",
      "Loss after iteration 26: 0.479112 (score=87.47%)\n",
      "Loss after iteration 27: 0.471923 (score=88.00%)\n",
      "Loss after iteration 28: 0.468033 (score=87.72%)\n",
      "Loss after iteration 29: 0.461550 (score=88.13%)\n",
      "Loss after iteration 30: 0.453708 (score=88.01%)\n",
      "Loss after iteration 31: 0.446998 (score=88.47%)\n",
      "Loss after iteration 32: 0.440693 (score=88.56%)\n",
      "Loss after iteration 33: 0.435303 (score=88.78%)\n",
      "Loss after iteration 34: 0.428599 (score=88.80%)\n",
      "Loss after iteration 35: 0.424505 (score=88.98%)\n",
      "Loss after iteration 36: 0.419919 (score=89.16%)\n",
      "Loss after iteration 37: 0.418287 (score=89.19%)\n",
      "Loss after iteration 38: 0.412745 (score=89.29%)\n",
      "Loss after iteration 39: 0.409576 (score=89.38%)\n",
      "Loss after iteration 40: 0.404962 (score=89.40%)\n",
      "Loss after iteration 41: 0.397570 (score=89.66%)\n",
      "Loss after iteration 42: 0.394894 (score=89.62%)\n",
      "Loss after iteration 43: 0.390618 (score=89.77%)\n",
      "Loss after iteration 44: 0.388955 (score=89.85%)\n",
      "Loss after iteration 45: 0.385136 (score=89.91%)\n",
      "Loss after iteration 46: 0.382227 (score=89.95%)\n",
      "Loss after iteration 47: 0.378416 (score=90.09%)\n",
      "Loss after iteration 48: 0.373242 (score=90.27%)\n",
      "Loss after iteration 49: 0.371675 (score=90.17%)\n",
      "Loss after iteration 50: 0.369072 (score=90.20%)\n",
      "Loss after iteration 51: 0.366441 (score=90.29%)\n",
      "Loss after iteration 52: 0.364761 (score=90.20%)\n",
      "Loss after iteration 53: 0.360505 (score=90.52%)\n",
      "Loss after iteration 54: 0.356976 (score=90.55%)\n",
      "Loss after iteration 55: 0.354501 (score=90.68%)\n",
      "Loss after iteration 56: 0.350281 (score=90.73%)\n",
      "Loss after iteration 57: 0.347978 (score=90.95%)\n",
      "Loss after iteration 58: 0.346722 (score=90.79%)\n",
      "Loss after iteration 59: 0.346387 (score=90.75%)\n",
      "Loss after iteration 60: 0.342827 (score=90.99%)\n",
      "Loss after iteration 61: 0.339656 (score=91.05%)\n",
      "Loss after iteration 62: 0.337324 (score=91.01%)\n",
      "Loss after iteration 63: 0.335930 (score=91.18%)\n",
      "Loss after iteration 64: 0.333920 (score=91.11%)\n",
      "Loss after iteration 65: 0.333390 (score=91.18%)\n",
      "Loss after iteration 66: 0.330326 (score=91.16%)\n",
      "Loss after iteration 67: 0.329840 (score=91.22%)\n",
      "Loss after iteration 68: 0.326164 (score=91.31%)\n",
      "Loss after iteration 69: 0.328033 (score=91.25%)\n",
      "Loss after iteration 70: 0.326048 (score=91.12%)\n",
      "Loss after iteration 71: 0.323941 (score=91.39%)\n",
      "Loss after iteration 72: 0.323184 (score=91.26%)\n",
      "Loss after iteration 73: 0.320744 (score=91.43%)\n",
      "Loss after iteration 74: 0.318890 (score=91.44%)\n",
      "Loss after iteration 75: 0.317076 (score=91.45%)\n",
      "Loss after iteration 76: 0.315001 (score=91.56%)\n",
      "Loss after iteration 77: 0.312612 (score=91.62%)\n",
      "Loss after iteration 78: 0.309926 (score=91.67%)\n",
      "Loss after iteration 79: 0.309183 (score=91.67%)\n",
      "Loss after iteration 80: 0.307569 (score=91.77%)\n",
      "Loss after iteration 81: 0.307749 (score=91.69%)\n",
      "Loss after iteration 82: 0.308788 (score=91.64%)\n",
      "Loss after iteration 83: 0.306288 (score=91.61%)\n",
      "Loss after iteration 84: 0.305308 (score=91.81%)\n",
      "Loss after iteration 85: 0.303962 (score=91.77%)\n",
      "Loss after iteration 86: 0.302008 (score=91.87%)\n",
      "Loss after iteration 87: 0.300958 (score=91.81%)\n",
      "Loss after iteration 88: 0.300336 (score=91.86%)\n",
      "Loss after iteration 89: 0.301229 (score=91.72%)\n",
      "Loss after iteration 90: 0.297508 (score=91.91%)\n",
      "Loss after iteration 91: 0.293893 (score=92.05%)\n",
      "Loss after iteration 92: 0.290218 (score=92.14%)\n",
      "Loss after iteration 93: 0.287007 (score=92.31%)\n",
      "Loss after iteration 94: 0.288154 (score=92.25%)\n",
      "Loss after iteration 95: 0.284542 (score=92.26%)\n",
      "Loss after iteration 96: 0.283862 (score=92.36%)\n",
      "Loss after iteration 97: 0.281894 (score=92.45%)\n",
      "Loss after iteration 98: 0.281573 (score=92.36%)\n",
      "Loss after iteration 99: 0.278317 (score=92.55%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit( Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T16:00:47.585501Z",
     "start_time": "2018-11-13T16:00:47.508352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score( Xtest, ytest )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "Load MNIST fashion dataset, it has the same dimensions as MNIST dataset <br/>\n",
    "https://keras.io/api/datasets/fashion_mnist/  <br/> \n",
    "Go to the sklearn MLPClassifier website, learn about parameters and try different ones to achieve the \n",
    "best accuracy on the test set <br/>\n",
    "Comment on bias (overfitting) and variance (underfitting) <br/>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fashion_mnist.load_data()\n",
    "\n",
    "(Xtrain, ytrain), (Xtest, ytest) = dataset\n",
    "\n",
    "n_train = len(Xtrain)\n",
    "n_test = len(Xtest)\n",
    "\n",
    "n_features = 28*28\n",
    "\n",
    "Xtrain = Xtrain.reshape( n_train, n_features )\n",
    "Xtest  = Xtest.reshape( n_test, n_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtrain[5000], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,50,25,10), max_iter=50,activation = 'tanh',\n",
    "                    solver='adam',random_state=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.20688073\n",
      "Iteration 2, loss = 0.85593121\n",
      "Iteration 3, loss = 0.83047140\n",
      "Iteration 4, loss = 0.85285325\n",
      "Iteration 5, loss = 0.81049400\n",
      "Iteration 6, loss = 0.82199273\n",
      "Iteration 7, loss = 0.77110529\n",
      "Iteration 8, loss = 0.76090328\n",
      "Iteration 9, loss = 0.77058761\n",
      "Iteration 10, loss = 0.76584441\n",
      "Iteration 11, loss = 0.72945047\n",
      "Iteration 12, loss = 0.69030737\n",
      "Iteration 13, loss = 0.70407379\n",
      "Iteration 14, loss = 0.71272864\n",
      "Iteration 15, loss = 0.69069462\n",
      "Iteration 16, loss = 0.71801830\n",
      "Iteration 17, loss = 0.67565382\n",
      "Iteration 18, loss = 0.65568202\n",
      "Iteration 19, loss = 0.67984601\n",
      "Iteration 20, loss = 0.67811801\n",
      "Iteration 21, loss = 0.65915369\n",
      "Iteration 22, loss = 0.66601314\n",
      "Iteration 23, loss = 0.68470917\n",
      "Iteration 24, loss = 0.66600530\n",
      "Iteration 25, loss = 0.64901019\n",
      "Iteration 26, loss = 0.65769294\n",
      "Iteration 27, loss = 0.65253506\n",
      "Iteration 28, loss = 0.62894377\n",
      "Iteration 29, loss = 0.62944847\n",
      "Iteration 30, loss = 0.60912096\n",
      "Iteration 31, loss = 0.60731457\n",
      "Iteration 32, loss = 0.62039839\n",
      "Iteration 33, loss = 0.63780013\n",
      "Iteration 34, loss = 0.61158294\n",
      "Iteration 35, loss = 0.64073782\n",
      "Iteration 36, loss = 0.63552747\n",
      "Iteration 37, loss = 0.62624099\n",
      "Iteration 38, loss = 0.65911792\n",
      "Iteration 39, loss = 0.65765959\n",
      "Iteration 40, loss = 0.62953098\n",
      "Iteration 41, loss = 0.64848455\n",
      "Iteration 42, loss = 0.65452230\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 50, 25, 10),\n",
       "              max_iter=50, random_state=1, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 50, 25, 10),\n",
       "              max_iter=50, random_state=1, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 25, 10),\n",
       "              max_iter=50, random_state=1, verbose=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7322333333333333"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7245"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0].shape\n",
    "# 784 x 100\n",
    "# 784 features, 100 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[1].shape\n",
    "# 100 x 50\n",
    "# 100 hidden units, 50 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 25)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[2].shape\n",
    "# 50 x 25\n",
    "# 50 hidden units, 25 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 10)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[3].shape\n",
    "# 25 x 10\n",
    "# 25 hidden units, 10 output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[4].shape\n",
    "# 10 x 10\n",
    "# 10 hidden units, 10 output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtest[2000], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = T-shirt/top\n",
    "# 1 = Trouser\n",
    "# 2 = Pullover\n",
    "# 3 = Dress\n",
    "# 4 = Coat\n",
    "# 5 = Sandal\n",
    "# 6 = Shirt\n",
    "# 7 = Sneaker\n",
    "# 8 = Bag\n",
    "# 9 = Ankle boot\n",
    "clf.predict(Xtest[2000].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change activation function to relu\n",
    "clf_relu = MLPClassifier(hidden_layer_sizes=(100,50,25,10), max_iter=50,activation = 'relu',\n",
    "                    solver='adam',random_state=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.49999539\n",
      "Iteration 2, loss = 1.71050899\n",
      "Iteration 3, loss = 1.38737408\n",
      "Iteration 4, loss = 1.05828677\n",
      "Iteration 5, loss = 0.77845129\n",
      "Iteration 6, loss = 0.70064403\n",
      "Iteration 7, loss = 0.64588515\n",
      "Iteration 8, loss = 0.60482133\n",
      "Iteration 9, loss = 0.56383247\n",
      "Iteration 10, loss = 0.53067457\n",
      "Iteration 11, loss = 0.51051739\n",
      "Iteration 12, loss = 0.48730022\n",
      "Iteration 13, loss = 0.46088087\n",
      "Iteration 14, loss = 0.44923616\n",
      "Iteration 15, loss = 0.43272835\n",
      "Iteration 16, loss = 0.42638197\n",
      "Iteration 17, loss = 0.39839221\n",
      "Iteration 18, loss = 0.38201564\n",
      "Iteration 19, loss = 0.38090286\n",
      "Iteration 20, loss = 0.36551067\n",
      "Iteration 21, loss = 0.35702596\n",
      "Iteration 22, loss = 0.35217876\n",
      "Iteration 23, loss = 0.34401964\n",
      "Iteration 24, loss = 0.34770727\n",
      "Iteration 25, loss = 0.34184581\n",
      "Iteration 26, loss = 0.32672691\n",
      "Iteration 27, loss = 0.32369572\n",
      "Iteration 28, loss = 0.32068179\n",
      "Iteration 29, loss = 0.31169541\n",
      "Iteration 30, loss = 0.30678936\n",
      "Iteration 31, loss = 0.31198827\n",
      "Iteration 32, loss = 0.30577375\n",
      "Iteration 33, loss = 0.29635640\n",
      "Iteration 34, loss = 0.29241488\n",
      "Iteration 35, loss = 0.28924839\n",
      "Iteration 36, loss = 0.28390761\n",
      "Iteration 37, loss = 0.27628604\n",
      "Iteration 38, loss = 0.28219037\n",
      "Iteration 39, loss = 0.27262438\n",
      "Iteration 40, loss = 0.26939324\n",
      "Iteration 41, loss = 0.26389341\n",
      "Iteration 42, loss = 0.27396287\n",
      "Iteration 43, loss = 0.26370523\n",
      "Iteration 44, loss = 0.25775136\n",
      "Iteration 45, loss = 0.25763454\n",
      "Iteration 46, loss = 0.25417919\n",
      "Iteration 47, loss = 0.25037460\n",
      "Iteration 48, loss = 0.24749375\n",
      "Iteration 49, loss = 0.24594325\n",
      "Iteration 50, loss = 0.24273428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abubakr/Desktop/github/Vistula/visenv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50, 25, 10), max_iter=50, random_state=1,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50, 25, 10), max_iter=50, random_state=1,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 50, 25, 10), max_iter=50, random_state=1,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_relu.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9206666666666666"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_relu.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8743"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_relu.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtest[2000], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = T-shirt/top\n",
    "# 1 = Trouser\n",
    "# 2 = Pullover\n",
    "# 3 = Dress\n",
    "# 4 = Coat\n",
    "# 5 = Sandal\n",
    "# 6 = Shirt\n",
    "# 7 = Sneaker\n",
    "# 8 = Bag\n",
    "# 9 = Ankle boot\n",
    "clf_relu.predict(Xtest[2000].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for tanh activation function:  0.7245\n",
      "Accuracy for relu activation function:  0.8743\n"
     ]
    }
   ],
   "source": [
    "# checking accuracy for different activation functions\n",
    "print(\"Accuracy for tanh activation function: \", clf.score(Xtest, ytest))\n",
    "print(\"Accuracy for relu activation function: \", clf_relu.score(Xtest, ytest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After changing activation function from tanh to relu, accuracy increased by 15%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
